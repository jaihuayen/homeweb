---
title: 'ResNet: Residual Network'
date: 2022-10-01
permalink: /posts/2022/09/blog-post-2/
tags:
  - Network Search
  - AI
---

許多的影像問題，基本上都是採取傳統的CNN來作為訓練的手段，但是當遇到模型的深度夠深時，會經常遇到訓練上的問題。因此產生今天我們所要介紹的paper：Deep Residual Learning for Image Recognition。[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)是2015年發布，並於2016年的CVPR2016獲得最佳論文獎。那就來看看這篇文章的內容吧！

---
# Chapter 1: Introduction
在過往的研究中，發現傳統的CNN在影像類的處理，尤其是影像分類問題，有著顯著的發展。並且在一些研究指出，模型的深度對於影像類的問題處理有著非常大的影響，然後當模型的深度越深時，通常表現的狀況越好。但是一個問題出現了

> 想要訓練一個好的模型，就是讓模型盡量堆越多層就好了嗎？

答案是否定的，原因可以來看一下這張圖片：

![](/homeweb/images/resnet/resnet-1.png)

從上圖可以發現，即使我們的層數加的比較多的時候，error卻比較高，這樣違反了我們剛開始所敘述的假設，因為當層數越多時，它產生了另外一個問題：類神經網路的退化問題(degradation problem)。但如果回到一個最基本的問題，如果多增加的層的部分，都不學習，都只單純地做恆等映射(identity mapping)，那應該最少模型的表現應該跟淺層模型一樣才是，但是卻出現了這個弔詭的狀況發生，因此這個問題的產生與我們的模型優化方式有非常大的關係。

於是來到此paper的重點，也就是提出了deep residual learning framework。此架構大致如下圖所示：

![](/homeweb/images/resnet/resnet-2.png)

這個結果使得原本的映射從$F(x)$變到$F(x)+x$，即使當殘差為0，也只是讓模型進行恆等映射，並不會讓此類神經網路性能下降。然而實際上殘差不會為0，更可以因此學習到新的特徵，從而提升此網路的性能。並且梯度消失(gradient vanishing)或梯度爆炸(gradient exploding)的問題因此解決。

# Chapter 2: Deep Residual Learning

在提到這個網路架構前，要先提一下在做類神經網路時，大家所認知的一個假設：

> 一個多非線性層的網路，可以近似任何複雜的函數。

在前面Figure 2中可以看到，我們要學習的函數從原本的$F(x)$變到$F(x)+x$，我們知道藉由原本的假設，應該都可以達到我們想要近似的函數，但是在Figure 1所看到的，退化問題會讓要近似該函數的過程中出問題，讓我們原本希望至少能夠達到恆等映射無法實現。在現實的狀況下，恆等映射很難真的實現，但透過Residual Learning，可以在某種程度上去近似恆等映射。

具體實現這個Residual Learning的方式即是架構出一個一個block，每個block的結構為

$$y=F(x,\{W_i\})+x$$

其中$F$以Figure 2舉例，$F$為$F=W_{2}\sigma(W_{1}x)$，$\sigma$為ReLU函數，並且在最後得到$y$後，再進行一次非線性映射(例如Figure 2中的$\sigma(y)$)。這樣的做法由於沒有增加額外的參數以及計算複雜度(計算資源消耗只有多了很微不足道的element-wise addition)。當$x$以及$F$的維度不同時，則透過一個$W_{s}$的線性轉換即可:

$$y=F(x,\{W_i\})+W_{s}x$$

# Chapter 3: Experiments
由於ResNet所發想的來源是VGG，因此ResNet會與一般的plain network以及VGG一同比較，其架構如下圖：

![](/homeweb/images/resnet/resnet-3.jpg)

第一組資料為有著1000個物件類別的ImageNet 2012的數據集，並訓練了128萬張圖片，並以5萬張驗證集的圖片判斷結果作為評估。最後用10萬張測試集的圖片作為最終結果。

結果如下圖：

![](/homeweb/images/resnet/resnet-4.png)

可以很清楚發現在普通的類神經網路下，退化問題會發生，但在ResNet上卻可以完美地避開這個問題。

在單一模型下的比較結果如下：

![](/homeweb/images/resnet/resnet-5.png)

在集成(ensemble)模型下的比較結果如下：

![](/homeweb/images/resnet/resnet-6.png)

在表現上ResNet的結果都相較於其他模型來得好。

在CIFAR-10資料集的表現結果如下：

![](/homeweb/images/resnet/resnet-7.png)

![](/homeweb/images/resnet/resnet-8.png)

再次驗證了上述所說的狀況。

# Conclusion

在跟其他的模型比時，ResNet有著較好的表現結果。在自身模型加深時，避開了退化問題，是一個非常重大的突破。

# 參考文獻
1. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).
2. He, K., Zhang, X., Ren, S., & Sun, J. (2016, October). Identity mappings in deep residual networks. In European conference on computer vision (pp. 630-645). Springer, Cham.