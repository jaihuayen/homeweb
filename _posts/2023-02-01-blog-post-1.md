---
title: 'DeepLog: Log資料異常值分析'
date: 2023-02-01
permalink: /posts/2023/02/blog-post-1/
tags:
  - Log Analysis
  - LSTM
  - AI
---

針對log的分析在許多資訊系統上的應用上有著很大的價值，例如異常值分析對於建立一個穩定的系統是一個很實用的分析方法。但是log的資料類型非常多樣，且各種數值的意義皆不相同，因此從log資料分析出有意義的結論是相對困難的。所以誕生出DeepLog，針對log資料提出一些系統性的分析方法。

Paper: [Link](https://www.cs.utah.edu/~lifeifei/papers/deeplog.pdf)

統整這篇的一些小資訊：
1. 方法採用Deep LSTM
2. 優勢為可以透過用戶反饋即刻學習，不僅是可以提升模型的準確度，也對於未來新的異常狀況有辦法處理

---

## 前言

目前在log資料分析的挑戰如下：
* 資料類型的不一致使得資料清洗以及建立模型相對困難
* 當出現新的異常狀況時，單純訓練一個二分類模型(正常與否)的幫助是有限的
* concurrency造成順序的問題使得序列的資訊部分消失
* 過往的分析大部分只取用log key做為分析用的資料，這樣損失許多有用的資訊，如metrics values

## DeepLog 架構

![](/homeweb/images/deeplog/deeplog-1.png)

## DeepLog資料型態

![](/homeweb/images/deeplog/deeplog-2.png)

## DeepLog模型型態

### Part I: Log Key Anomaly Detection Model

方法：透過log key的順序進行建模，透過key的類型$\{k_1, k_2, ... , k_n\}$訓練一個n類的多分類模型，當下一個出現的類別出現在模型預測的前$g$類(須自行定義)，則視為一個normal case。反之則為abnormal case。

模型建構方式為採用Deep LSTM做為預測的模型。Loss為categorical cross-entropy，window為$h$.

![](/homeweb/images/deeplog/deeplog-3.png)

### Part II: Parameter Value Anomaly Detection Model

方法：每種log key各自建立模型。假如我們拿到上方Table 1的資料時，則我們將此資料整理為$\{[t_2 - t_1, 0.61], [t_2' - t_1', 1],...\}$的數據並建模。同時考慮執行時間以及此key給出的參數數值，可以使得偵測異常值有更多的維度視角。

模型建構方式為採用Deep LSTM，並建立一個多變量時間序列模型，損失函數為MSE。比起過往直接透過設定一個threshold判斷是否為異常值，這裡的方法比較特別。一開始將資料切分為training set以及validation set，training data進行模型訓練，並將validation輸入模型中，透過將模型的執行結果與validation的資料計算MSE，並把兩者資料的差異以常態分佈建構信賴區間。如果超過信賴區間的數值，則視為異常值。

### Part III: Online Update of Models

方法：直接透過真實的新數據(有人進行false-positive的反饋)進行微調(fine-tuning)即可，不需要重新訓練模型

## DeepLog Workflow (Skip)

## Results

### Part I: Log Key Anomaly Detection Model

資料來自於(1) 執行Hadoop-based map-reduced工作所產生的log，以及(2) 於OpenStack上面建構VM所產生的log。資料的類型整理如下：

![](/homeweb/images/deeplog/deeplog-4.png)

執行的結果如下表：

![](/homeweb/images/deeplog/deeplog-5.png)


可以看出在HDFS的資料集上，DeepLog達到top-5 accuracy到達99.8% (top-1 accuracy為88.9%，仍是相當高)。DeepLog在F1-Score的表現上也是相較於其他方法來說最好的。在OpenStack的資料集中，DeepLog在F1-Score的表現上仍然是最好的。

並且在模型訓練的時候，調整其中的超參數。結果發現超參數對於模型的表現效果影響不大，這樣也代表著在真實的情境中，這類型的模型比較好去讓他上線，而不會因為對於超參數的選擇而有很大的表現差異。

![](/homeweb/images/deeplog/deeplog-6.png)

### Part II: Parameter Value Anomaly Detection Model

在這個部分利用OpenStack VM的創造時間作為此實驗的目標。並在過程中製造DoS攻擊，造成網路的速度變慢，並觀察VM的創造時間，檢測模型是否可以抓到此異常狀況。

![](/homeweb/images/deeplog/deeplog-7.png)

圖9(a)以及(b)為正常情況下的log value，圖9(c)以及(d)為非正常情況下的log key值，其中有兩個時間為非正常的狀況。可以看出針對非正常的情況下的log value，建構的信賴區間皆可以精準的偵測到異常狀態。

### Part III: Online Update of Models

![](/homeweb/images/deeplog/deeplog-8.png)

上圖比較是否有做即時學習對於模型的表現，由圖可以清楚發現，有給予模型反饋並微調，可以讓模型的表現狀況提升許多。如果在沒有進行即時學習時，由於在training dataset中無法涵蓋到全部的異常狀況(甚至可以說以長期來看只包含到少部分的異常狀況)，即使我們給他更多的訓練資料，也對於模型的效果提升有限。

## 結論

此篇研究給了我們未來在做機器上的異常值檢定，有一個明確的方向以及框架。