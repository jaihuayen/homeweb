---
title: 'R-CNN: Region-based Convolutional Neural Networks'
date: 2022-10-15
permalink: /posts/2022/10/blog-post-1/
tags:
  - Object Detection
  - AI
---

當我們不僅希望知道該圖片的物件類別，並且可以準確定位該物件的位置，此時物件偵測則變成一件非常重要的事情。其應用非常廣泛，在生態研究中，可以快速定位出想要觀察到的物種，對於生態學家們可以更容易取得研究所需的資料。在自駕車的開發中，知道前方的物件為何，對於電腦判斷車的行走方向以及行駛速度都有著非常大的影響。因此[R-CNN](https://arxiv.org/pdf/1311.2524.pdf)(Region-based Convolutional Neural Networks)的產生，對於該領域的研究有著開創的影響。

---

## Chapter 1: Introduction
過往許多的電腦視覺領域中，將CNN的運算在最尾端加上一個分類器，用以對該影像中無論是物件或是背景的分類。但是當我們希望去定位該物件的位置時，==我們不僅僅需要知道他的位置，還需要匡出它的大小==。這即是這篇文章所希望處理的問題，並因此提出R-CNN。R-CNN的大致運作流程如下圖：

![](/homeweb/images/rcnn/rcnn-1.png)

**1. 輸入資料**
**2. 生成候選區域：** 利用[Selective Search](https://zhuanlan.zhihu.com/p/39927488)對一張圖像生成大約2000個候選區域
**3. 特徵擷取：** 利用CNN對每個候選區域進行特徵擷取，擷取出一個4096維的特徵向量。
**4. 分類判斷：** 對於每個候選區域所截取的特徵，送入每一類的SVM分類器，判斷是否為該類別的物件
**5. 位置修正：** 利用regression修正位置的精確度

## Chapter 2：Object detection with R-CNN

### 2.1  Input and Preprocess Image Data
這部分主要討論上面提到的第一步與第二步。透過selective search找到2000個候選區域，再對候選區域進行resize為227x227，以滿足後面CNN的輸入。文章中提到resize最好的方式，以單純對候選區域加上padding=16(padding是直接取該區域周圍的影像，如果補的部分不夠，則利用該區域平均的RGB數值對應的顏色補上)。最後將padding完的影像進行resize。

![](/homeweb/images/rcnn/rcnn-2.jpg)

![](/homeweb/images/rcnn/rcnn-3.jpg)

### 2.2 CNN and Classification on Region Proposals

#### 2.2.1 CNN Feature Extraction

本文使用[AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)，因為跟VGG16比運算量少了將近7倍。並利用此模型最後p5層9216維度的輸出接出來的fully connected layer設定為4096，使得照片經過CNN模型擷取出來的特徵為4096維。

![](/homeweb/images/rcnn/rcnn-4.png)

#### 2.2.2 Model Training

在文章中提到由於可用來訓練模型的標註圖片(同時標注圖片類別以及位置)數量較少，因此遷移學習在此就相當重要，將在較大的圖片分類資料集(ILSVRC2012)訓練的預訓練模型，利用小量的圖片物件標注資料(PASCAL)進行微調。這樣的遷移學習對於訓練的效果有顯著的提升。

透過前一步取出4096維的特徵後，輸入SVM後，針對每一個希望訓練的類別進行訓練。在此訓練的資料中，標註為正樣本的為與正確標注的資料位置相交IoU最大且大於0.6的候選區域。

在物件位置的部分，由於經常候選區域不夠精確，仍然需要修正。在此使用ridge regression ($\lambda=10000$)，輸入為4096維的特徵數據後，輸出為框的中間xy位置以及該框的width和height。


#### 2.2.3 Model Inference

圖像讀入後，透過selective search選出候選區域，將resize過後的候選區域輸入CNN中，特徵選取完，輸入已經訓練好的SVM模型，對候選區域們進行評分，通過IOU進行NMS，得到該類的bounding-box。

---


## 參考文章：
1. Girshick, R., Donahue, J., Darrell, T., & Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. *In Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 580-587). [Link](https://arxiv.org/pdf/1311.2524.pdf)
2. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. *Advances in neural information processing systems*, 25. [Link](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
3. Uijlings, J. R., Van De Sande, K. E., Gevers, T., & Smeulders, A. W. (2013). Selective search for object recognition. International journal of computer vision, 104(2), 154-171. [Link](https://staff.fnwi.uva.nl/th.gevers/pub/GeversIJCV2013.pdf)
4. [RCNN- 将CNN引入目标检测的开山之作](https://zhuanlan.zhihu.com/p/23006190)
5. [R-CNN论文详解](https://blog.csdn.net/WoPawn/article/details/52133338)